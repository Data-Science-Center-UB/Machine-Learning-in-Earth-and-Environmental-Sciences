{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea51bf7-572f-4a26-be71-2adcd41f20d7",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b4bac-5b13-4d48-bb58-d1ccb072581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scikit-learn scipy pygam openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e602b3a-da70-4767-9075-bd3ad46afdc4",
   "metadata": {},
   "source": [
    "# Interpretable Models\n",
    "\n",
    "Whenever possible, simpler, interpretable machine learning (ML) models should be used. While they may sacrifice some predictive accuracy, they offer greater scientific value by enhancing transparency and understanding. Moreover, they often serve as a foundation for building deeper insights into complex systems.\n",
    "\n",
    "Model interpretability can vary in degree. Some models may be fully interpretable (like sparse linear models or a single decision tree; often referred to as white box models), while others may be only partially interpretable. Even complex models can offer interpretability at the level of components (e.g., feature coefficients) or predictions (e.g., nearest neighbor examples or decision paths). In contrast, black box models (e.g., neural networks) are not interpretable by design and require post-hoc explanation methods (Molnar 2025; Dwiwedi et al. 2023; see Notebooks 3 and 4).\n",
    "\n",
    "This notebook introduces a range of inherently interpretable or semi-interpretable models: linear regression, logistic regression, Generalized Additive Models (GAMs), and decision trees. In addition, unsupervised methods: Principal Component Analysis (PCA), hierarchical clustering, and K-means clustering. These models provide varying degrees of transparency into how predictions are made or how structure in the data can be understood.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../Images/XAI_By_Design.png\" style=\"width: 400px;\">\n",
    "  <div style=\"font-size: 14px; margin-top: 8px;\">Fig. 1 Overview of interpretability methods in machine learning, modified from Molnar (2025)</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ec2b9-c796-4988-b66c-758df2060b9a",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 1. Linear regression\n",
    "\n",
    "**Linear models** form one of the core building blocks of (supervised) ML. These models make predictions by combining features linearly and this assumption makes linear models easy to interpret, fast to train, and efficient to scale. A linear model can only fit lines and will not chance shape to accommodate other data patterns. In other words, they work best when the relationship between input and output is approximately linear. However, since this is the case for many environmental datasets, satisfactory performances from linear models can be often reached (Veronesi and Schillaci 2019).\n",
    "\n",
    "In Python, linear models are implemented in scikit-learn under `sklearn.linear_model`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674ab10-e213-4e3b-a993-3be2e94effcf",
   "metadata": {},
   "source": [
    "---\n",
    "Let's see how to use the linear regression model to predict soil moisture influenced by temperature and humidity (example modified from GeoSMART 2025):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b5de6-785e-4fc3-b3ab-396ee77f968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d6d73-264a-4c21-af1b-370dfb700eb4",
   "metadata": {},
   "source": [
    "Create some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2ac0f-1cdb-4a12-a433-bb91af00c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "n_samples = 300\n",
    "\n",
    "# Generate environmental variables\n",
    "temperature = np.random.uniform(15, 35, n_samples)  # in degrees Celsius\n",
    "humidity = np.random.uniform(30, 90, n_samples)      # in percentage\n",
    "\n",
    "# Generate soil moisture as a function of temperature and humidity\n",
    "soil_moisture = (\n",
    "    0.5 * humidity - 0.3 * temperature + np.random.normal(0, 2, n_samples)\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Temperature': temperature,\n",
    "    'Humidity': humidity,\n",
    "    'Soil Moisture': soil_moisture\n",
    "})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35275740-a3f5-455d-a999-fd3a7db1994b",
   "metadata": {},
   "source": [
    "Data visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e0c7c-ec23-4989-b6c0-87b0d4037f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data['Temperature'], data['Humidity'], data['Soil Moisture'], color='blue')\n",
    "ax.set_xlabel('Temperature (°C)')\n",
    "ax.set_ylabel('Humidity (%)')\n",
    "ax.set_zlabel('Soil Moisture')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf709d-2585-4abd-9559-54360fd170e3",
   "metadata": {},
   "source": [
    "Split data between training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dce972-6823-40dc-9a78-bf0f89d9b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Temperature', 'Humidity']]\n",
    "y = data['Soil Moisture']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520b698-f532-4138-bc20-87faf5634172",
   "metadata": {},
   "source": [
    "Choose model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd58959-5c8e-45c9-8b88-ecce98bad517",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f28d6-3ab6-4ba8-9a3e-6f4347ee2def",
   "metadata": {},
   "source": [
    "Evaluate model performance on test set using Mean Square Error (MSE) and R score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c5c21-b2ab-40cd-8ca2-c295628508fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"mean square error {mse} and R2 {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e359ee0d-b17c-43d3-a602-2dd8e5fa63b4",
   "metadata": {},
   "source": [
    "Plot original data and fitted surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9feb28-a586-4ab0-bdfc-1128c8db59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid to evaluate model\n",
    "temp_range = np.linspace(X['Temperature'].min(), X['Temperature'].max(), 30)\n",
    "hum_range = np.linspace(X['Humidity'].min(), X['Humidity'].max(), 30)\n",
    "temp_grid, hum_grid = np.meshgrid(temp_range, hum_range)\n",
    "\n",
    "# Flatten the grid and make predictions\n",
    "grid_points = np.c_[temp_grid.ravel(), hum_grid.ravel()]\n",
    "moisture_pred = regressor.predict(grid_points).reshape(temp_grid.shape)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X['Temperature'], X['Humidity'], y, color='blue', label='Data', alpha=0.5)\n",
    "ax.plot_surface(temp_grid, hum_grid, moisture_pred, color='orange', alpha=0.6, label='Fit')\n",
    "ax.set_xlabel('Temperature (°C)')\n",
    "ax.set_ylabel('Humidity (%)')\n",
    "ax.set_zlabel('Soil Moisture')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af85ee-642f-4ac0-8ccf-e7d52b050055",
   "metadata": {},
   "source": [
    "### **Interpretation:**\n",
    "\n",
    "Once the model is trained, you can access the learned coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2771c-6d8a-4ead-9b2a-e646cfe21510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept (b):\", regressor.intercept_)\n",
    "print(\"Coefficients (w):\", regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525685be-6efb-47ad-a042-2c5e0630af4e",
   "metadata": {},
   "source": [
    "The general form of a multiple linear regression model is:\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $y$ is the predicted soil moisture  \n",
    "- $x_1$ is temperature  \n",
    "- $x_2$ is humidity  \n",
    "- $\\beta_0$ is the intercept  \n",
    "- $\\varepsilon$ is the error term\n",
    "\n",
    "After training, the model learned:\n",
    "\n",
    "- $\\beta_0 = 1.71$  \n",
    "- $\\beta_1 = -0.33$  \n",
    "- $\\beta_2 = 0.48$\n",
    "\n",
    "So the model becomes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = 1.71 - 0.33 \\cdot \\text{Temperature} + 0.48 \\cdot \\text{Humidity}\n",
    "$$\n",
    "\n",
    "For every +1 °C, soil moisture **decreases** by 0.33 units.  \n",
    "For every +1% humidity, soil moisture **increases** by 0.48 units.  \n",
    "\n",
    "With an $R^2$ of 0.95, the model explains **95% of the variance** in soil moisture. This is a strong linear fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda40f5-8518-4c1f-899e-cf9dbcd55d49",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 2. Logistic Regression\n",
    "\n",
    "Logistic regression is actually a classification method. Linear regression can technically be used to separate classes by fitting a line, but it outputs values below 0 or above 1, which are not valid probabilities.\n",
    "\n",
    "Logistic regression solves this by using the **logistic (sigmoid) function** to **squeeze the output** of a linear model between 0 and 1. This outputs a probability, which we can threshold (e.g., at 0.5) to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41148c-c04a-43ac-b8a6-4ddc70a8059b",
   "metadata": {},
   "source": [
    "---\n",
    "Let's create a logistic regression model to classify different species of penguins from their physical characteristics using the Palmer's Penguins dataset from the `seaborn` library. This dataset contains morphological measurements (such as bill length and body mass) of three penguin species — Adélie, Chinstrap, and Gentoo — collected from islands in the Palmer Archipelago, Antarctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be8ba5-a57d-462d-919f-1224c5fc906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183bb32-2f7f-40c3-87f8-b6fafffd9ddc",
   "metadata": {},
   "source": [
    "Get and select data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea1e14-b451-40f6-999c-b2c077678829",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins = penguins.drop(columns=['island', 'sex'])\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57cea9-6475-437e-add0-9f393f7f246d",
   "metadata": {},
   "source": [
    "Drop rows with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b35d9a-a4e9-4af3-9ef5-3ce53207fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f6df0-8ffd-4c56-b658-3c2bf00170f2",
   "metadata": {},
   "source": [
    "Encode species column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b6f0a-59d8-436d-8be1-911f28213e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "penguins['species_label'] = le.fit_transform(penguins['species'])\n",
    "print(penguins['species_label'].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4458d1-dcb6-4566-ad09-b70b8ebfd3e9",
   "metadata": {},
   "source": [
    "Select features and target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3b0ad-eea4-464f-8e6f-9593e2c24a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "y = penguins['species_label']\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2942433-ef3b-4090-91b4-39950dac9fa4",
   "metadata": {},
   "source": [
    "Split data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d06cd-0a8b-4643-9c54-569df6d4b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.4,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d502472-d98a-4526-a7a8-e3a345505416",
   "metadata": {},
   "source": [
    "Scale features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c14580-fc23-44ad-9a5f-5198d6f27db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e0a22-a4dd-400f-9bef-d6cf953e9181",
   "metadata": {},
   "source": [
    "Train and predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc71c36-93f2-4b42-9247-36622ff2b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039ad33-ecc1-4a19-aa59-ba731940a885",
   "metadata": {},
   "source": [
    "Evaluate using typical **metrics for a classification tasks**: \n",
    "- **precision:** The proportion of predicted positive cases that are actually positive. High precision means fewer false positives.\n",
    "- **recall:** The proportion of actual positive cases that were correctly predicted. High recall means fewer false negatives.\n",
    "- **f1-score:** The harmonic mean of precision and recall, balancing the two.\n",
    "\n",
    "All range from 0 to 1 (or 0% to 100% if expressed as percentages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44617bdc-9602-4046-a673-c9ef1e7d1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c68a0-640d-40d4-b572-d0ac35dacfc2",
   "metadata": {},
   "source": [
    "Note: We can’t directly plot the logistic regression decision boundary in 2D with 4 features. However, we can directly investigate the model coefficients (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557abadb-eb31-488c-9dcf-85613ebd3519",
   "metadata": {},
   "source": [
    "### **Interpretation:**\n",
    "\n",
    "Getting coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163c4ef-9de5-4401-a45b-45582ef10d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(\n",
    "    model.coef_,\n",
    "    columns=feature_names,\n",
    "    index=le.classes_  # rows = one-vs-rest for each class\n",
    ")\n",
    "\n",
    "print(\"=== Coefficients (log-odds) ===\")\n",
    "print(coef_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe152ed4-2a47-4bca-af13-45290a493cce",
   "metadata": {},
   "source": [
    "The model is linear in the features, but the output is converted to a probability via the logistic function:\n",
    "\n",
    "$$\n",
    "\\log\\left( \\frac{P(y = \\text{class})}{1 - P(y = \\text{class})} \\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "- $P(y = \\text{class})$ is the probability of a penguin belonging to a specific species  \n",
    "- $x_1, x_2, \\dots$ are physical features (e.g., bill length, flipper length)  \n",
    "- $\\beta_0$ is the intercept  \n",
    "- The left-hand side is called the **log-odds**\n",
    "\n",
    "Each row in the coefficient table represents a logistic regression classifier for one species versus the rest. The coefficients describe how a 1 standard deviation change in a feature affects the log-odds of that class:\n",
    "- Positive coefficients: increase the log-odds, i.e. higher probability\n",
    "- Negative coefficients: decrease the log-odds, i.e. lower probability\n",
    "\n",
    "Example for the species \"Chinstrap\":\n",
    "\n",
    "Log-odds (linear part):\n",
    "\n",
    "$$\n",
    "z_{\\text{Chinstrap}} = 2.030 \\cdot x_1 + 0.364 \\cdot x_2 - 0.681 \\cdot x_3 - 1.243 \\cdot x_4\n",
    "$$\n",
    "\n",
    "Probability (after applying sigmoid):\n",
    "\n",
    "$$\n",
    "P(\\text{Chinstrap}) = \\frac{1}{1 + e^{-z_{\\text{Chinstrap}}}} = \\frac{1}{1 + e^{-(2.030 x_1 + 0.364 x_2 - 0.681 x_3 - 1.243 x_4)}}\n",
    "$$\n",
    "\n",
    "Logistic regression belongs to the **Generalized Linear Model (GLM)** framework. This extends linear regression to handle: \n",
    "- Non-Gaussian outcomes (e.g. binary, counts)\n",
    "- Non-identity link functions (e.g. logit, log)\n",
    "\n",
    "In the case of logistic regression:\n",
    "- The distribution is Bernoulli (binary outcomes)\n",
    "- The link function is the logit (log-odds)\n",
    "- The linear predictor is the same: $\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n$\n",
    "\n",
    "All GLMs share the following structure:\n",
    "\n",
    "$$\n",
    "g(\\mathbb{E}[y]) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbb{E}[y]$ is the expected value of the outcome\n",
    "- $g$ is the link function (e.g., identity, log, logit)\n",
    "- The right-hand side is a linear combination of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8493ae-26ab-4128-97c3-374edded2845",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 3. Beyond Learning Linear Relationships: Generalized Additive Models (GAMs)\n",
    "\n",
    "Generalized Additive Models (GAMs) extend generalized linear models by allowing **nonlinear relationships** between features and the outcome, while preserving the **additive structure** and **interpretability**.\n",
    "\n",
    "The general form of a GAM is:\n",
    "\n",
    "$$\n",
    "g(\\mathbb{E}[y]) = \\beta_0 + f_1(x_1) + f_2(x_2) + \\cdots + f_n(x_n)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\mathbb{E}[y]$ is the expected value of the outcome\n",
    "- $g$ is a link function (e.g., identity, log, logit)  \n",
    "- Each $f_j(x_j)$ is a **smooth function** of a single feature  \n",
    "- If $f_j(x_j) = \\beta_j x_j$, it's a standard linear term\n",
    "\n",
    "GAMs model the outcome as a **sum of feature effects, each potentially nonlinear**. A GAM predicts an outcome by adding together the effects of several predictors. Each effect can be:\n",
    "- A straight line (linear term), or\n",
    "- A smooth curve (spline), to capture nonlinear patterns. \n",
    "\n",
    "In de la Iglesia Martinez & Labib (2024), GAM was used to explore how different types of green vegetation (like tree canopy, grass, shrubs) relate to NDVI (a measure of greenness derived from satellite remote sensing data), across various spatial buffers (100 m, 300 m, 500 m). They tested linear-only models, spline-based models, and mixed-models (some linear, some smooth). In a different study, Schäfer et al. (2022) modeled how environmental and temporal factors affect river electrical conductivity over time. Both studies provide data and code to follow their implementations of GAMs: All predictors were modeled with splines (nonlinear). Both studies used the identity link function because it suits linear regression purposes and the dependent variables were identified to following a normal distribution. They used the `LinearGam` from `pyGAM`, which already uses a normal distribution and identity link.\n",
    "\n",
    "The **link function** defines how the model connects the expected value of the outcome to the additive predictor (the sum of smooth feature effects). For example, the identity link keeps predictions on the original scale of the outcome, making interpretation more direct. GAMs model nonlinear effects of predictors through **smooth functions**, while the link function determines how those effects combine to predict the outcome: either directly (identity) or on a transformed scale (e.g. log or logit), depending on the nature of the response variable. Examples of other link functions than the identity are discussed, e.g., in Molnar 2025. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed2cba-61f7-4515-af5f-c8a98a0c2de9",
   "metadata": {},
   "source": [
    "---\n",
    "### LinearGAM modified from Ian SHEN, Medium\n",
    "\n",
    "Let's replicate the red wine quality prediction example by [Ian SHEN, Medium](https://medium.com/just-another-data-scientist/building-interpretable-models-with-generalized-additive-models-in-python-c4404eaf5515). We'll use the `LinearGAM` model from the `pyGAM` library, which applies the identity link function by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323b55c-c84f-41ae-b153-38158969d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse\n",
    "scipy.sparse.spmatrix.A = property(lambda self: self.toarray())  # fake the .A attrib to fix bug in PyGAM 0.9.1\n",
    "from pygam import LinearGAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618018c0-e94d-4a28-907b-48db96e4b311",
   "metadata": {},
   "source": [
    "Import and prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e0dcd-3c74-4c6e-aced-fe5c30ae06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names based on the UCI Wine Quality dataset documentation\n",
    "redwine_url = 'https://raw.githubusercontent.com/ianshan0915/medium-articles/master/data/redwine-quality.csv'\n",
    "redwine = pd.read_csv(redwine_url)\n",
    "\n",
    "# Preview the first few rows\n",
    "redwine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4094b2-7b9d-4d19-9bb7-9a385765f7d5",
   "metadata": {},
   "source": [
    "Select & split data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a51f9-981b-4384-a314-901c21183cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target_feature = 'quality'\n",
    "features = redwine.columns.drop(target_feature).tolist()\n",
    "\n",
    "X = redwine[features]\n",
    "y = redwine[target_feature]\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf14cf0-ce05-4dcb-bc47-45d6ff012a73",
   "metadata": {},
   "source": [
    "GAMs introduce smoothing parameters that control non-linearity (how flexible the splines are). Because of these **smoothing parameters**, GAMs have hyperparameters that need to be tuned. This introduces an important consideration: **Do not use test data during hyperparameter tuning.** Instead, you can use either cross-validation (on training data) or a separate validation set. **Grid search** is a method that systematically tests multiple combinations of parameters to find the set that minimizes a chosen error metric. \n",
    "\n",
    "When we call `gridsearch()` in `pyGAM`, we're doing grid search with built-in cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d738b5f-cb44-40dd-a254-7e32e6295017",
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = np.random.rand(100, 11)\n",
    "lams = lams * 11 - 3\n",
    "lams = np.exp(lams)\n",
    "print(lams.shape)\n",
    "gam = LinearGAM(n_splines=10).gridsearch(X_train.values, y_train.values, lam=lams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cababb-4387-444d-aafd-b1b994589ce1",
   "metadata": {},
   "source": [
    "Evaluate the model by using two error metrics: MAE (Mean Absolute Error), which measures the average magnitude of prediction errors, and sMAPE (Symmetric Mean Absolute Percentage Error), which expresses prediction accuracy as a percentage, making it scale-independent and symmetric around the actual and predicted values. These metrics help evaluate how well the GAM model predicts PM2.5 concentrations on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf396b-2d96-4806-9348-e29e042e7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(abs(y_test - gam.predict(X_test)))\n",
    "y_pred = gam.predict(X_test)\n",
    "smape = 100 * np.mean(2 * np.abs(y_test - y_pred) / (np.abs(y_test) + np.abs(y_pred)))\n",
    "print(smape)\n",
    "\n",
    "print(gam.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea6922-cb86-4a9a-8850-62e58ad0a4e8",
   "metadata": {},
   "source": [
    "The SMAPE is pretty good. It means the model's predictions are off by ~9% on average, relative to the true value. However, the pseudo R² of ~0.41 shows that the model only explains about 41% of the total variance in the outcome, meaning there’s still substantial unexplained variability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c17e52-1a5c-4f81-b31c-360782492a7d",
   "metadata": {},
   "source": [
    "### **Interpretation:**\n",
    "\n",
    "**Partial dependence plots** in a GAM show how a single feature contributes to the model’s prediction, while holding other features constant. In GAMs, these effects are represented by the model's component functions — either splines (for nonlinear relationships) or linear terms. The y-axis in a partial dependence plot does not show the actual predicted outcome. It shows the magnitude and direction of a feature's additive contribution relative to the model's baseline (the intercept).\n",
    "\n",
    "Plot partial dependence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ffce0-09ad-4416-87cc-d5e7756454b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = features[0:11]\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1,11,figsize=(40, 8))\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX))\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX,   width=.95)[1], c='r', ls='--')\n",
    "    if i == 0:\n",
    "        ax.set_ylim(-30,30)\n",
    "    ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757fb8f-b2a2-42aa-ade6-9863b7e671dc",
   "metadata": {},
   "source": [
    "We can explain that: \n",
    "\n",
    "- Higher levels of volatile acidity, chlorides, total sulfur dioxide, density and pH are generally linked to lower wine quality scores.\n",
    "- In contrast, increases in residual sugar and free sulfur dioxide tend to be associated with higher quality scores.\n",
    "- The effects of sulphates, and alcohol are more nuanced. For example, wine quality tends to peak when the alcohol content is around 13%; values above or below that level can reduce the quality score.\n",
    "- Fixed acidity appears to have minimal impact on quality.\n",
    "- The effect range of alkohol is largest. We can therefore say that alkohol has the strongest overall influence.\n",
    "- The red dashed lines represent 95% confidence intervals, showing the uncertainty around the estimated effect of each feature. In some plots (e.g., volatile acidity, citric acid, density), the intervals are wide in certain regions — especially at the feature extremes — indicating higher uncertainty in those areas due to fewer observations or greater variability. This means predictions in those regions should be interpreted more cautiously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb151c04-2b02-4c65-aa27-18c7dece3839",
   "metadata": {},
   "source": [
    "Let's investigate the intercept to better understand how the y-axis values in the partial dependence plots (PDPs) are determined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6dc3d-cb10-42b1-8fc7-fcd6d4af6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gam.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fa7e9-2bf8-4079-b2d4-148621b92c37",
   "metadata": {},
   "source": [
    "In a GAM, as in any regression model, the intercept depends on the scale and distribution of the input data.\n",
    "\n",
    "In summary, we don't usually interpret the absolute y-axis values in PDPs. Instead, we focus on: \n",
    "- The direction of the curve (positive or negative influence)\n",
    "- The shape of the relationship (linear, nonlinear, flat, U-shaped, etc.)\n",
    "- The range of the curve (how much the feature affects the prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9e649-0e3f-4986-87d2-d290ecc23839",
   "metadata": {},
   "source": [
    "---\n",
    "### LinearGAM modified from Schäfer et al. (2022)\n",
    "\n",
    "Let's replicate the results of that study for a single measurement site: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba556c1-d34c-4fd0-8eed-03c5ef38c3b6",
   "metadata": {},
   "source": [
    "Load and clean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75615cd-15cd-488e-86a6-97852452d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/Schäfer_et_al_2022/2019-2020 15 minute resolution (wide).csv')\n",
    "data['Date'] = [datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\") for t in data['Date']]\n",
    "data['Station'] = data['Station'].replace({'Site 1': 'BH', 'Site 2': 'LC', 'Site 3': 'LP', 'Site 4': 'WB'})\n",
    "\n",
    "dataClean = pd.read_csv('../Data/Schäfer_et_al_2022/water_quality_data_clean.csv')\n",
    "riverLevel_raw = pd.read_excel('../Data/Schäfer_et_al_2022/Rickmansworth Stage June 2019 to 2020.xlsx')\n",
    "riverLevel = riverLevel_raw[20:].dropna()[0:365*4*24+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9192cf4-e469-4cd5-9b02-f477ebc8623b",
   "metadata": {},
   "source": [
    "Set station and prepare features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec53cd-c707-4134-abf9-ead68fcd71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationName = 'LP'\n",
    "sampleData = dataClean[dataClean['Station'] == stationName]\n",
    "dates = sampleData['Date'].tolist()\n",
    "\n",
    "# Align river level\n",
    "riverLevelDates = np.array(riverLevel['Station name'].tolist())\n",
    "riverLevelValues = np.array(riverLevel['RICKMANSWORTH'].tolist())\n",
    "riverLevelAligned = [riverLevelValues[np.where(riverLevelDates == datetime.strptime(str(date), \"%Y-%m-%d %H:%M:%S\"))[0][0]] for date in dates]\n",
    "\n",
    "# Extract features\n",
    "temperatureList = sampleData['Temperature...C.'].tolist()\n",
    "rainFallList = sampleData['Rainfall..mm.'].tolist()\n",
    "electricalConductivityList = sampleData['Electrical.conductivity..μS.cm.'].tolist()\n",
    "pHList = sampleData['pH'].tolist()\n",
    "oxygenList = sampleData['Dissolved.oxygen..mg.L.'].tolist()\n",
    "monthList = [datetime.strptime(str(d), \"%Y-%m-%d %H:%M:%S\").month for d in sampleData['Date'].tolist()]\n",
    "dayList = [datetime.strptime(str(d), \"%Y-%m-%d %H:%M:%S\").weekday() for d in sampleData['Date'].tolist()]\n",
    "hourList = [datetime.strptime(str(d), \"%Y-%m-%d %H:%M:%S\").hour for d in sampleData['Date'].tolist()]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Temperature': temperatureList,\n",
    "    'Rainfall': rainFallList,\n",
    "    'Month': monthList,\n",
    "    'Day': dayList,\n",
    "    'Hour': hourList,\n",
    "    'Dissolved.oxygen..mg.L.': oxygenList,\n",
    "    'Electrical.conductivity..μS.cm.': electricalConductivityList,\n",
    "    'pH': pHList,\n",
    "    'River level': riverLevelAligned\n",
    "}).dropna().reset_index(drop=True)\n",
    "\n",
    "# Investigate the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab1136-a260-434e-8fb6-eed572be2a60",
   "metadata": {},
   "source": [
    "Split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb4ef4-edec-4d58-802d-c450f2b673fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = 'Electrical.conductivity..μS.cm.'\n",
    "features = ['Temperature','Rainfall','Month','Day','Hour','pH','River level']\n",
    "X = df[features]\n",
    "Y = df[targetFeature]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc90e6-2907-4707-83fa-b8636d5602a9",
   "metadata": {},
   "source": [
    "Grid search (this takes some time to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba083e2-da9f-43c0-a294-07d8d4d342cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define lambda values to search over\n",
    "lam_values = np.logspace(-3, 10, 8)\n",
    "\n",
    "bestPrediction = None\n",
    "bestMAE = float('inf')\n",
    "bestGAM = None\n",
    "\n",
    "for n_spline in range(6, 16):\n",
    "    gam = LinearGAM(n_splines=n_spline).gridsearch(X_train.to_numpy(), Y_train.to_numpy(), lam=lam_values)\n",
    "    mae = np.mean(np.abs(Y_test - gam.predict(X_test.to_numpy())))\n",
    "    \n",
    "    print(f\"MAE={mae:.4f} for n_splines={n_spline}\")\n",
    "    \n",
    "    if mae < bestMAE:\n",
    "        bestMAE = mae\n",
    "        bestPrediction = n_spline\n",
    "        bestGAM = gam\n",
    "\n",
    "print(f\"\\nBest MAE={bestMAE:.4f} for n_splines={bestPrediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997055d1-a08f-41b0-9ad3-b4b0f737a948",
   "metadata": {},
   "source": [
    "Fit GAM with 10 splines as in publication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b20174-39cb-40be-a8be-09b3f361346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = LinearGAM(n_splines=10).gridsearch(X_train.to_numpy(), Y_train.to_numpy()) # .gridsearch(...) tells pyGAM to tune the smoothing penalty automatically (by default uses  default internal grid )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01b4e9-dda7-4f0f-ad7d-cd40c78cb777",
   "metadata": {},
   "source": [
    "Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f24ad-b9a4-47b3-9802-fc38bf0ac977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mae = np.mean(abs(Y_test - gam.predict(X_test)))\n",
    "Y_pred = gam.predict(X_test)\n",
    "smape = 100 * np.mean(2 * np.abs(Y_test - Y_pred) / (np.abs(Y_test) + np.abs(Y_pred)))\n",
    "\n",
    "print(smape)\n",
    "print(gam.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978e9b5-a008-4247-b64c-b37e7440e3e1",
   "metadata": {},
   "source": [
    "The model’s performance was very good, with a SMAPE (Symmetric Mean Absolute Percentage Error) of 1.623% (in the publication), indicating that on average, the predicted EC values differed from the observed ones by just 1.6%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb66ba-9d8e-42aa-a86c-336f45da7960",
   "metadata": {},
   "source": [
    "Print intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de4557-75cb-42b0-a2d4-752bb533f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gam.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269e42e-fc85-4213-9417-53cab0998d98",
   "metadata": {},
   "source": [
    "The intercept relates to the original data values. `pyGAM` does not center the smooth functions around zero (like `mgcv` in R). This means that the contributions of smooth functions can be entirely positive or negative, and the intercept compensates to bring the final predictions close to observed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7b756-b835-4c0a-9dbe-7d317ef93f52",
   "metadata": {},
   "source": [
    "Plot partial dependence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83a804-727b-4ba9-9086-b48cb6e6e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = X_train.columns\n",
    "unitTitles = [\n",
    "    f'{titles[0]} [°C]',\n",
    "    f'{titles[1]} [mm]',\n",
    "    titles[2],\n",
    "    titles[3],\n",
    "    titles[4],\n",
    "    f'{titles[5]}',\n",
    "    f'{titles[6]} [mAOD]'\n",
    "]\n",
    "\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(1, len(titles), figsize=(32, 8))\n",
    "plt.rc('font', size=22)\n",
    "for i, ax in enumerate(axs):\n",
    "    XX = gam.generate_X_grid(term=i)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX), linewidth=3.0)\n",
    "    ax.plot(XX[:, i], gam.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--', linewidth=3.0)\n",
    "    ax.set_xlabel(unitTitles[i], fontsize=26)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('EC [μS/cm]')\n",
    "        ax.legend(['Fit', 'Confid.'])\n",
    "    if i == 3:\n",
    "        ax.set_title(f'{stationName}, SMAPE={round(smape, 2)}%', fontsize=26)\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080756e-7d84-4076-a8ce-98510c05b33f",
   "metadata": {},
   "source": [
    "> ### **Exercise 1:**\n",
    "> Analyze the outputs of the GAM and evaluate the implications of partial dependence plots. Discuss:\n",
    "> 1. What are the most influential predictors for EC in the model?\n",
    ">    \n",
    "> 2. What effect did the individual predictors had on EC values?\n",
    ">\n",
    "> 3. The PDP for temperature is entirely above 0. What does this tell you about the effect of temperature on EC?\n",
    ">\n",
    "> 4. Below are six common limitations of GAMs, especially in relation to the trade-off between interpretability and model flexibility. For each one, think about what is meant by each limitation.\n",
    "> - Limited interpretability of scale compared to linear regression\n",
    "> - No interaction modeling unless specified\n",
    "> - Need for feature selection\n",
    "> - Interpretation depends on model tuning\n",
    "> - Confidence in feature effects can vary\n",
    "> - Link functions other than the identity function complicate interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5c8e5-aa11-4819-80c1-70a6c1c26bda",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 4. Summary: Linear Models\n",
    "Linear models are a powerful and widely accepted foundation for both prediction (regression and classification) and statistical inference. Over time, many extensions, such as GAMs, have been developed to overcome the limitations of strict linearity while retaining much of the interpretability. However, as these models incorporate nonlinear effects, link functions, and interactions, they become more complex and hence less interpretable. The extensions help bridge the gap to the flexibility often required in geoscientific applications, but they also come with added assumptions and challenges. In practice, more complex ML models may offer better predictive performance, though often at the further expense of transparency and explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d135a-5a41-4b85-a285-f0cc7b20b1ab",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 5. Decision Trees\n",
    "\n",
    "Compared to linear models, decision trees are predictive models that are especially useful when the relationship between features and the outcome is nonlinear or when features interact in complex ways. They base decisions on **value thresholds**, not on distances of the input. This characteristic allows them to handle both numerical and categorical data (also mixtures of both in the same tree), without requiring feature scaling or transformation. As non-parametric models, they make no assumptions about the underlying data distribution, giving them added flexibility. Furthermore, decision trees perform automatic feature selection as part of the model training process. However, decision trees have a tendency to overfit the training data, especially when they grow deep and complex. To prevent overfitting, it’s important to ensure that each split significantly reduces prediction error. This can be managed through hyperparameter tuning.\n",
    "\n",
    "A decision tree **splits data step-by-step based on feature values**. At each step, the algorithm chooses the feature and cut-off that best separates the data to reduce error using MSE for regression or Gini index for classification. This process continues until a stopping rule is met (like a minimum number of data points per node). \n",
    "\n",
    "Fig. 2 below is illustrating the tree terminology: The top of the tree is called the **root node**. From the root node, data is splitted into **branches** with internal nodes (or decision nodes) that have arrows pointing to them and arrows pointing away from them. The final groups are called **leaf nodes**, and each one gives a prediction (the average outcome of training data in that leaf node). In summary, this step-by-step splitting of the data means the tree creates simple \"if–then\" rules: \"If feature A > 3 AND feature B ≤ 1, then predict 250.\" In regression, 250 would be the average of the target values of the training samples that fall into that leaf. In classification, the prediction at a leaf is typically the most frequent class among the samples in that leaf.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../Images/DTs.png\" style=\"width: 350px;\">\n",
    "  <div style=\"font-size: 14px; margin-top: 8px;\">Fig. 1 Structure and terminology of a Decision Tree. </div>\n",
    "</div>\n",
    "\n",
    "### **Interpretation:**\n",
    "\n",
    "Decision trees are highly interpretable, because their rules are:\n",
    "- Sequential and transparent reasoning: A prediction is made by following a single path from the root to a terminal leaf node. Each decision in the path is based on a simple rule involving one feature, making it easy to trace and understand the logic behind a prediction.\n",
    "- Visual representation: Decision trees can be visualized as flowcharts or tree diagrams.\n",
    "- Feature-based structure: Each internal node of a decision tree corresponds to a split on a single feature. This allows users to identify which features are most influential for a particular prediction, and to rank features based on their overall impact on the tree.\n",
    "- Feature importance: Decision trees can estimate feature importance based on the total reduction in a criterion such as MSE (for regression) or Gini index/entropy (for classification) brought by each feature across all splits where it is used.\n",
    "\n",
    "However, the interpretability of decision trees comes with limitations:\n",
    "- Step-function approximation: Decision trees approximate relationships between features and the response with axis-aligned splits, resulting in step-like, piecewise constant functions. This can lead to predictions that are abrupt and may not align well with smooth underlying trends (especially in regression).\n",
    "- Complexity in deep trees: While small trees are easy to interpret, it's becoming more difficult to interpret deep trees. As the number of splits increases, so does the cognitive load required to understand the full model.\n",
    "- Instability: Decision trees are non-robust. A small change in the training data can lead to a completely different tree structure, which undermines the consistency of interpretations and makes model explanations harder to trust in sensitive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a086f84-a55a-4b21-ba64-66502f8ff154",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Tree Regressor Compared to Linear Regression (inspired by Josh Starmer, YouTube)\n",
    "\n",
    "Let's create a synthetic dataset to illustrate how a decision tree regressor works and how it compares to linear regression, following the example by [Josh Starmer (YouTube)](https://www.youtube.com/watch?v=g9c66TUylZ4). The scenario models an experiment to find the optimal drug dosage for patients. Imagine a clinical trial was conducted where different dosages were administered, and the effectiveness of the drug was measured. If the relationship between dosage and effectiveness were simple, such as higher dosages leading to higher effectiveness, then a linear regression model could be used to fit a straight line to the data. However, in our artificial dataset, both low and high dosages are ineffective, while moderate dosages produce high effectiveness. There is also a slight decline in effectiveness at slightly higher moderate dosages. This results in a non-linear, non-monotonic relationship that a straight line cannot accurately capture. We need to use something other than a straight line to make predictions, like a regression tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f5b2f-816a-4be3-a8f8-455d7fad6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cd795-02c4-415c-a35a-d86d6898deae",
   "metadata": {},
   "source": [
    "Create dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d2485-f8e5-4d81-9f0b-451b7270ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate dosage and effectiveness for different segments\n",
    "dosage_low = np.random.uniform(0, 10, 8)\n",
    "effectiveness_low = np.random.uniform(0, 5, 8)\n",
    "\n",
    "dosage_mid_rise = np.random.uniform(11, 13, 3)\n",
    "effectiveness_mid_rise = np.random.uniform(20, 30, 3)\n",
    "\n",
    "dosage_high_effective = np.random.uniform(14, 20, 7)\n",
    "effectiveness_high_effective = np.random.uniform(95, 100, 7)\n",
    "\n",
    "dosage_mid_drop = np.random.uniform(25, 29, 6)\n",
    "effectiveness_mid_drop = np.random.uniform(55, 70, 6)\n",
    "\n",
    "dosage_high = np.random.uniform(31, 39, 6)\n",
    "effectiveness_high = np.random.uniform(0, 5, 6)\n",
    "\n",
    "# Combine all\n",
    "dosage = np.concatenate([dosage_low, dosage_mid_rise, dosage_high_effective,\n",
    "                         dosage_mid_drop, dosage_high])\n",
    "effectiveness = np.concatenate([effectiveness_low, effectiveness_mid_rise,\n",
    "                                effectiveness_high_effective, effectiveness_mid_drop,\n",
    "                                effectiveness_high])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(dosage, effectiveness, color='orange', edgecolor='black', s=20)\n",
    "plt.xlabel(\"Drug Dosage (mg)\", fontsize=12)\n",
    "plt.ylabel(\"Drug Effectiveness (%)\", fontsize=12)\n",
    "plt.title(\"Synthetic Drug Dosage vs Effectiveness\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05126fb-cb58-4ea9-b8c0-2e7ed7aaa4c9",
   "metadata": {},
   "source": [
    "Define features and target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efab4f-a081-4907-8dde-ced2a2a99a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dosage.reshape(-1, 1)\n",
    "y = effectiveness\n",
    "feature_names = ['dosage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b568f1-8bf9-4dd3-a7f4-702e504a4e1b",
   "metadata": {},
   "source": [
    "Split into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282229fd-4014-40f3-aaf4-56c5d80abfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66875ac-274b-4cf6-bf5d-de716d60ada1",
   "metadata": {},
   "source": [
    "First, we fit a linear regression to this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e203160-a25f-4f88-b3c5-88fa891451b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the same X_fit range as used for the tree\n",
    "X_fit = np.linspace(X.min(), X.max(), 500).reshape(-1, 1)\n",
    "y_fit_lin = lin_reg.predict(X_fit)\n",
    "\n",
    "# Predict on test set and evaluate\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "mse = np.mean((y_test - y_pred_lin) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Test set MSE: {mse:.2f}\")\n",
    "print(f\"Test set RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Plot fitted line\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(X, y, color='orange', edgecolor='black', s=20, label='Data')\n",
    "plt.plot(X_fit, y_fit_lin, color='green', linewidth=2, label='Linear Regression Prediction')\n",
    "plt.xlabel(\"Drug Dosage (mg)\", fontsize=12)\n",
    "plt.ylabel(\"Drug Effectiveness (%)\", fontsize=12)\n",
    "plt.title(\"Linear Regression Fit\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb9d97-441b-4cec-9e78-bddc92e0f7f7",
   "metadata": {},
   "source": [
    "Next, we fit a regression tree with limited depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6dc8e-4159-41d7-a42b-57317d7261b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = DecisionTreeRegressor(max_depth=3, random_state=0) # Note: Leaf nodes do not count as another depth level\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d052d-6da7-4283-a3df-610d9c06cb09",
   "metadata": {},
   "source": [
    "After fitting a fully grown tree we apply hyperparameter tuning of the cost-complexity pruning parameter (`ccp_alpha`). This helps prevent overfitting by simplifying the tree after it has been trained.\n",
    "\n",
    "Note: While we are only tuning the pruning parameter here, decision trees have several other important hyperparameters that can be tuned during training, such as: `max_depth` (maximum depth of the tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a71dd3-c871-4a13-9a98-60b6e06069d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_path = reg.cost_complexity_pruning_path(X_train, y_train) # ceates a list of different pruning levels\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=10) # sets up 5-fold cross-validation\n",
    "\n",
    "# Try each value of ccp_alpha from the ccp_path.ccp_alphas, and use cross-validation to test which works best:\n",
    "grid = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(max_depth=3, random_state=0),\n",
    "    param_grid={'ccp_alpha': ccp_path.ccp_alphas},\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=kfold,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "G = grid.fit(X_train, y_train) # Running the cross validation and pick the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9ee6c-fbe8-47e7-9318-cb946a2930c0",
   "metadata": {},
   "source": [
    "Evaluate the best estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f966d0-ea4e-4923-ab6d-67d0f56fa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Test set MSE: {mse:.2f}\")\n",
    "print(f\"Test set RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416400b-24bf-486b-9002-8e3128e1fc0a",
   "metadata": {},
   "source": [
    "The RMSE of 2.75 is much better compared to linear regression, which had an RMSE of 55.90. An RMSE of 2.97 is also very good in absolute terms. Since the effectiveness values in our dataset range from 0% to 100%, an average prediction error of about 3 percentage points indicates that the tree-based model is producing highly accurate estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaecd81-419f-49ee-b377-11c7246d444a",
   "metadata": {},
   "source": [
    "Let's plot the regression tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5906ff4-1253-4158-a3a7-2d2574ca4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "plot_tree(best_model, feature_names=feature_names, filled=True, ax=ax, fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d6959bf-afe8-4e1c-aab7-c72bb84ee5c6",
   "metadata": {},
   "source": [
    "What do the boxes show (from top to bottom)?\n",
    "1. the split condition for this node\n",
    "2. variance of target value in this node\n",
    "3. number of training samples that reached this node\n",
    "4. the average predicted value at this node\n",
    "\n",
    "Note: In a classification task, the variance is replaced by a measure of impurity, such as Gini index, and the prediction shows the most frequent class in that node (and the class distribution).\n",
    "\n",
    "We can make clear, rule-based decisions from this tree, such as \"If 13.624 < dosage ≤ 22.051, then predict 98.2% effectiveness.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9402a-08a1-484a-9993-1453d1e0e5c3",
   "metadata": {},
   "source": [
    "Let's plot the fitted decision tree regression curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb87e0c-295d-44a5-a82f-b7bb279328a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smooth range of dosage values for prediction\n",
    "X_fit = np.linspace(X.min(), X.max(), 500).reshape(-1, 1)\n",
    "y_fit = best_model.predict(X_fit)\n",
    "\n",
    "# Plot data and fitted model\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, color='orange', edgecolor='black', s=100, label='Data')\n",
    "plt.plot(X_fit, y_fit, color='blue', linewidth=2, label='Regression Tree Prediction')\n",
    "plt.xlabel(\"Drug Dosage (mg)\", fontsize= 12)\n",
    "plt.ylabel(\"Drug Effectiveness (%)\", fontsize= 12)\n",
    "plt.title(\"Decision Tree Fit\", fontsize= 12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75579ba-25ae-49a2-b6e1-d7118bc7b5e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Tree Classifier with Mixed Features\n",
    "\n",
    "Next, we'll fit a tree classifier using the Palmer Penguins dataset (see Sect. 2). The dataset includes numerical and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc016e-ab80-460b-99ee-3c559ef638df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b1e8b-6ff4-4338-9c52-de010aa6a0d6",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ba280-f705-45d3-b086-7fbcc256c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins = penguins.dropna()\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533114af-2e4a-4331-92c8-918e2ef90e99",
   "metadata": {},
   "source": [
    "Separate features and target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a804c-70b5-4016-86a5-c1e19cab7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = penguins.drop(columns=['species'])\n",
    "y = penguins['species']\n",
    "feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c33731-2095-4774-8759-2a21dfc31821",
   "metadata": {},
   "source": [
    "Encode categorical features (e.g. OneHotEncoder, OrdinalEncoder): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1070b9-8a1d-43d4-a30d-316b1a22ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "encoder = OrdinalEncoder()\n",
    "X[categorical_cols] = encoder.fit_transform(X[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d10e9f-24fc-4d75-940c-3e22bb671963",
   "metadata": {},
   "source": [
    "Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8747632-d068-4447-a94e-51489dbd935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d35451-a986-42af-adee-aee4ed793f85",
   "metadata": {},
   "source": [
    "Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc745f-6da0-4408-b6bb-ce1d435ac1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe16cf7-012f-4fdd-ad4b-88722631e480",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173935b-5ccf-42ef-84ea-eb8aa98b9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5c07a-59ef-43aa-939e-df66d10aa6ad",
   "metadata": {},
   "source": [
    "Let's skip hyperparameter tuning and directly evaluate and interpret this initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a811c64-cb02-4a1b-9bcf-58540177a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 5))\n",
    "plot_tree(clf, feature_names=feature_names, class_names=clf.classes_, filled=True, rounded=True, fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad438a8-33be-4fc4-b8c1-bc1b639dd7ac",
   "metadata": {},
   "source": [
    "The decision tree is using four features: flipper_length_mm, bill_length_mm, island, and bill_depth_mm. These features contribute to class separation by how much they reduce the Gini index at each split, weighted by the number of samples passing through them (the \"value\" list in the tree).\n",
    "\n",
    "The most important feature is at the root: flipper_length_mm, with a threshold of 206.5 mm, splits all 333 training samples and immediately separates most Adelie penguins (left, 208 samples) from others (right, 125 samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202506c7-71e7-434d-8163-55a8d3b447fd",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 6. Unsupervised Learning\n",
    "\n",
    "Let's switch to some of the unsupervised ML tasks, namely **dimensionaly reduction** via **Principal Component Analysis (PCA)** and **clustering**, specifically **hierarchical clustering** and **K-means clustering**. Both methods are used to simplify the data via a smaller number of summaries, but their mechanisms are different:\n",
    "- PCA aims to create a simplified version of the data by projecting it onto a lower-dimensional space that still captures most of the original variability.\n",
    "- Clustering seeks to divide the data into groups of similar observations, where items within each group are alike and distinct from those in other groups.\n",
    "\n",
    "To demonstrate unsupervised learning we import the Iris dataset from the `scikit-learn` library. The dataset contains 150 samples of iris flowers from three labeled species (setosa, versicolor, virginica), with each sample including four features. We assume there are no labels for the unsupervised learning tasks of this section; however, we can use these labels to evaluate how well the algorithms describe or separate the true classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8bc22-14ad-426c-810e-467f26e4073c",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd942a3d-9ee2-4020-b67e-484973b92eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris_data['data'], columns = iris_data['feature_names'])\n",
    "iris_df['target'] = iris_data['target'] \n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07841baa-106f-4f8b-ae06-9426d9e7986d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 6.1 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d2e911-f19b-42ca-a83d-9502ae92ffb8",
   "metadata": {},
   "source": [
    "PCA is a method for reducing the dimensionality of a dataset by finding new variables. **Principal components** are linear combinations of the original variables and explain the most variance in the data: Each component is formed by multiplying the original features by a set of weights (called loadings) and summing them up. The first principal component (PC1) is the direction in feature space where the data vary the most. The second principal component (PC2) is uncorrelated with PC1 and captures the next highest variance. Standardization is essential before applying PCA, unless all features are on the same scale. Otherwise, PCA will prioritize variables with larger variances due to units, not importance.\n",
    "\n",
    "Of course, non-linear dimensionality reduction techniques also exist. However, these methods are often harder to interpret or reproduce, as the transformations are more complex. A prominent example of a non-linear technique is t-SNE.\n",
    "\n",
    "### **Interpretation:**\n",
    "\n",
    "Principal components can capture meaningful directions in the data (e.g., overall \"size\" or \"intensity\") and the loadings show how much each original variable contributes to each principal component. However, principal components are not totally interpretable, because each component is a mix of all original variables. The transformation is linear but abstract, so the new axes may not correspond to intuitive real-world concepts unless the data structure supports it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22290d5e-cdb6-4b97-85c9-3379bc69c372",
   "metadata": {},
   "source": [
    "---\n",
    "We apply a PCA to the iris dataset. This example is modified from [scikit-learn.org](https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638a685-fc6e-4bae-8821-c0a0816dd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167004cf-a028-4866-9ca9-2bb6b57076e1",
   "metadata": {},
   "source": [
    "We scale the data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b2c9a-b111-414d-9634-dee5f08537c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4fe62-e955-4b3e-ad2b-e415d19ad7e2",
   "metadata": {},
   "source": [
    "Run PCA to create 3 new features that are a linear combination of the 4 original features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bdd4c-f410-49cd-afe7-43f9b7410592",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_reduced = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9c455-7fd7-4ade-bcd5-7e19b50c9c10",
   "metadata": {},
   "source": [
    "Next, plot the irises across the three PCA dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca29f43-788b-4922-a886-0ae2a6b789a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\", elev=-150, azim=110)\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    X_reduced[:, 2],\n",
    "    c=iris_data.target,\n",
    "    cmap=\"viridis\",\n",
    "    s=40,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    title=\"First three PCA dimensions\",\n",
    "    xlabel=\"1st Eigenvector\",\n",
    "    ylabel=\"2nd Eigenvector\",\n",
    "    zlabel=\"3rd Eigenvector\",\n",
    ")\n",
    "ax.xaxis.set_ticklabels([])\n",
    "ax.yaxis.set_ticklabels([])\n",
    "ax.zaxis.set_ticklabels([])\n",
    "\n",
    "# Add a legend\n",
    "legend1 = ax.legend(\n",
    "    scatter.legend_elements()[0],\n",
    "    iris_data.target_names.tolist(),\n",
    "    loc=\"upper right\",\n",
    "    title=\"Classes\",\n",
    "    fontsize=12\n",
    ")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfab6c-8ff4-4c4e-aebf-88ac3e53f25a",
   "metadata": {},
   "source": [
    "We can differentiate among the three types. With this transformation, we see that we can identify each species using only the first feature (i.e., first eigenvector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ad0db-13c3-4f8c-b18f-f0e4e8b61d5b",
   "metadata": {},
   "source": [
    "Let's inspect the loadings and explained variance using attributes of the PCA object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72529800-b80e-4aba-839e-623a27068a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a4989-ffb8-474c-80ff-1c7b9db956bf",
   "metadata": {},
   "source": [
    "PC1 explains 72.96% of the variance, PC2 explains 22.85%, and PC3 explains 3.67%. So, the first two components together explain over 95% of the total variance. This is a strong indication that most of the structure in the data can be captured in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc904a-150b-4d50-98f1-edd8873aa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61744b8-50b7-4e58-bfd4-3ed054725496",
   "metadata": {},
   "source": [
    "Each row represents one principal component; each column represents the contribution (loading) of an original feature. For example:\n",
    "\n",
    "PC1 =  0.521×x1  - 0.269×x2  + 0.580×x3  + 0.565×x4\n",
    "\n",
    "This tells us how each original feature contributes to each principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b371592-f307-4eb3-b227-a46c11df7780",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 6.2 Clustering\n",
    "\n",
    "Clustering is a fundamental unsupervised ML technique used to identify subgroups (clusters) within a dataset. The aim is to group observations such that those in the same cluster are similar, while those in different clusters are dissimilar. The definition of similarity is generally domain-specific, relying on the nature and context of the data.\n",
    "\n",
    "Two very famous clustering approaches are:\n",
    "\n",
    "1. **K-means Clustering**:\n",
    "- Requires pre-specifying the number of clusters.\n",
    "- Partitions data to minimize within-cluster variance.\n",
    "\n",
    "2. **Hierarchical Clustering**:\n",
    "- Does not require pre-specifying the number of clusters.\n",
    "- Produces a dendrogram, a tree-like diagram showing nested cluster structures (nice for interpretation). Here,\n",
    "    - The root represents one large cluster containing all samples\n",
    "    - The leaves represent individual samples.\n",
    "\n",
    "Note: \n",
    "- When dealing with high-dimensional data, applying **PCA** before clustering is a widely applied strategy.\n",
    "- Both clustering approaches generally use **Euclidean distance** (straight-line distance between two points in space). Since Euclidian distance is sensitive to the scale of features, it is generally recommended to scale features before clustering to ensure that each variable contributes equally to the distance calculations.\n",
    "\n",
    "`scikit-learn` offers a variety of clustering algorithms. Additionally, [scikit-learn.org](https://scikit-learn.org/stable/modules/clustering.html) provides a helpful comparison of various clustering methods on synthetic datasets with helpful visualizations, which is useful for comparing the strengths and limitations of different algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b6f4e-3d08-405c-b393-3ced4651c19b",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 6.2.1 Hierachical Clustering\n",
    "\n",
    "Hierarchical clustering is a family of clustering methods that builds a hierarchy of clusters by either merging (agglomerative) or splitting (divisive) clusters. Hierarchical clustering is implemented in `scikit-learn` as `AgglomerativeClustering`. The most common type of hierarchical clustering is **bottom-up or agglomerative clustering**. Here, the **dendrogram** (a tree-like diagram) is build by starting with individual data points and progressively merging them into larger clusters (James et al. 2023). \n",
    "\n",
    "In hierarchical clustering, the choice of the dissimilarity measure and linkage (ways to measure distance between clusters) heavily influences the final clustering result and should be selected based on the specific data and goal. The most common dissimilarity measure is **Euclidean distance**, and a widely used linkage method is **Ward’s method**, which minimizes the total within-cluster variance. \n",
    "\n",
    "### **Interpretation:**\n",
    "\n",
    "Good explainability of hierarchical clustering comes from the dendrogram it produces. This visual structure allows us to trace the clustering process and choose the number of clusters by \"cutting\" the tree at a desired level.\n",
    "\n",
    "However, its accuracy and validity (and in turn, its interpretability) become limited when:\n",
    "\n",
    "- The dataset is high-dimensional, where distances become less meaningful due to the curse of dimensionality (see Notebook 1; Sect. 3.3).\n",
    "- The dendrogram becomes too complex or cluttered with large datasets.\n",
    "- The underlying data structure is not hierarchical, making the resulting tree arbitrary or misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993639d-680b-49c0-b07e-4f7dd7afdf3d",
   "metadata": {},
   "source": [
    "---\n",
    "Let's continue with clustering the Iris data using the described method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7031e-fa5c-46ee-b800-fa9822f82c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec5b0-b69e-41ef-8e97-d78896b72665",
   "metadata": {},
   "source": [
    "We scale the data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07593ee-4f63-4d4f-96fc-01e6e7551738",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5346d-be22-4fb0-b30a-54df5997395d",
   "metadata": {},
   "source": [
    "Run the clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb617526-7173-4fba-938f-792afe1b3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None) # setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = model.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f872644-3bc5-4303-a14a-059e3c3ce8a9",
   "metadata": {},
   "source": [
    "We now want to plot the dendrogram. `AgglomerativeClustering` provides pairs of cluster indices that were merged at each step (`children_`) and the distance between those merged clusters (`distances_`). But `scipy.dendrogram()` also needs to know how many original data points (samples) are in each merged cluster. So in a loop, each time two clusters are merged, the following code:\n",
    "- Checks if the merged items are original samples (leaf nodes) or previously formed clusters.\n",
    "- Adds up the number of samples they contain.\n",
    "- Stores that count so it can be used in later merges.\n",
    "\n",
    "The final linkage matrix has 4 columns:\n",
    "- Index of the first cluster merged\n",
    "- Index of the second cluster merged\n",
    "- Distance between the two clusters\n",
    "- Number of samples in the new (merged) cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703bd737-a7e9-42bf-af63-49e96b725b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linkage_matrix(model):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # it's a leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
    "    return linkage_matrix\n",
    "\n",
    "linkage_matrix = create_linkage_matrix(model)\n",
    "\n",
    "linkage_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbbe18-d662-4f79-8957-3d83dcd424fc",
   "metadata": {},
   "source": [
    "We can now plot the dendrogram using the linkage matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c0d7f-3132-4bdc-b54f-732df741e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3)) \n",
    "dendrogram(linkage_matrix)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caad49d-0764-4cdd-a2d5-55007106ff4a",
   "metadata": {},
   "source": [
    "The dendrogram indicates three distinct clusters, with one (on the left) clearly separated at a large distance threshold. This suggests that there are three Iris species with one Iris species is more distinct, while the other two are more similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2877b01-1ba5-4356-9252-bd7e712d6fd3",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 6.2.2 K-means Clustering\n",
    "\n",
    "K-means clustering devides a dataset into **K non-overlapping clusters**. To use K-means, you first choose the number of clusters, K. The algorithm then assigns each data point to exactly one of these clusters based on similarity. The goal is to group points in such a way that the within-cluster variation is minimized: Points within the same cluster should be as similar to each other as possible. Similarity is measured using **Euclidean distance**.\n",
    "\n",
    "The algorithm works as follows:\n",
    "- It starts by randomly assigning each observation to one of the K clusters. Because of this randomness the algorithm is typically run multiple times with different random initializations (starting points).\n",
    "- It then repeatedly performs two steps until the assignments stop changing:\n",
    "    - It calculates the centroid (mean) of each cluster.\n",
    "    - It reassigns each observation to the cluster whose centroid is closest in terms of Euclidean distance.\n",
    "\n",
    "### **Interpretation:**\n",
    "\n",
    "K-means is relatively easy to interpret because it creates clusters based on proximity to centroids, with each cluster represented by the mean of its points. \n",
    "\n",
    "However, it assumes that clusters are convex, isotropic (equally spread in all directions), and of similar size, which often doesn't reflect the true structure of real-world data. As a result, clustering accuracy and validity (and in turn, its interpretability) become limited when:\n",
    "- The actual clusters are irregularly shaped (e.g., elongated, curved)\n",
    "- Clusters are overlapping or vary significantly in size or density\n",
    "- The dataset is high-dimensional, where Euclidean distances lose meaning due to the curse of dimensionality.\n",
    "\n",
    "In addition, a key limitation is the need to specify the number of clusters, K, in advance. Choosing the right K is a practical challenge and often requires additional methods or domain knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14897601-f735-4b72-89e1-d973a5daeb65",
   "metadata": {},
   "source": [
    "---\n",
    "Let's also cluster the Iris dataset using K-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98361671-fc97-4f61-b23d-84f7211f71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5301b2-389d-42ad-88eb-afe89de088b6",
   "metadata": {},
   "source": [
    "We scale the data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac9a61-d29e-4576-bfb3-618091631b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59696f0c-5453-46a4-9a0b-8a598044fead",
   "metadata": {},
   "source": [
    "Finding the optimum number of clusters for k-means classification (up to 10 clusters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6fc70-71ba-416f-8763-e6692ad38e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    # max_iter is maximum number of iterations\n",
    "    # n_init=10 runs the algorithm 10 times with different centroid seeds\n",
    "    # random_state=0 for reproducibility (can be any number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738fcc0-410d-4f12-96d9-d59f56cba990",
   "metadata": {},
   "source": [
    "Using the **elbow method** to determine the optimal number of clusters for K-means clustering. It works by running the clustering algorithm for a range of cluster counts (as above) and it measures how well the data fits the clustering by looking at the cluster centers. As K increases, the metric usually decreases sharply at first and then levels off. The point where the decrease slows down and forms an “elbow” indicates the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2596b2-ecdc-41a5-8634-1f6b2da9dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The elbow method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS') #within cluster sum of squares\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79f011-57f9-4425-ae0a-104b4ff58550",
   "metadata": {},
   "source": [
    "Run K-Means with optimal number of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a45390-2778-47fa-83c6-57dcd0d93f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27984201-fd99-4898-8213-9f11ce6ea185",
   "metadata": {},
   "source": [
    "Visualize the clusters in 2D, i.e. with first two components (features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864f17a-c256-4840-badc-2c8ab6ad88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plot each cluster seperately\n",
    "plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s=30, c='purple', label = 'C1')\n",
    "plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s=30, c='orange', label = 'C2')\n",
    "plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s=30, c='green', label = 'C3')\n",
    "\n",
    "# Plot centroids\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0],\n",
    "            kmeans.cluster_centers_[:, 1],\n",
    "            c='black', s=50, label='Centroids')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"K-means Clustering (2D)\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7012886-6de2-4819-b8e4-8e28e413038a",
   "metadata": {},
   "source": [
    "Various methods exist in `sklearn.metrics` to evaluate the success of the clustering. The **Silhouette Score** and **Calinski-Harabasz Score** are two famous metrics if the data does not have ground truth labels:\n",
    "- Silhouette Score: Measures how similar a data point is to its own cluster compared to other clusters. It ranges from -1 to 1. A higher score means the clusters are well-separated and cohesive.\n",
    "- Calinski-Harabasz Score: Evaluates the ratio of between-cluster dispersion to within-cluster dispersion. Higher values indicate better-defined and more separated clusters. On its own, the Calinski-Harabasz Score is not \"high\" or \"low\" in absolute terms, but it is meaningful when compared to scores from other values of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea768f9-0fc2-4566-a513-6c25f84db5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(X, y_kmeans)\n",
    "print(f\"Average silhouette score: {silhouette_avg:.3f}\")\n",
    "ch_score = calinski_harabasz_score(X, y_kmeans)\n",
    "print(f\"Calinski-Harabasz Score: {ch_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3e4b4-4647-4717-9117-dc7a07cbc675",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 6.3 Unsupervised Learning in Mishra et al. (2022) to Support Supervised Learning\n",
    "\n",
    "In Mishra et al. (2022), k-Means clustering and PCA were used together to explore the internal structure of well log data and its correspondence with geological lithologies. The final aim of using k-means clustering was to automatically identify lithological classes from well log data as a precursor to building a predictive model for lithology and reservoir characterization. K-means clustering was applied as the first step in a two-fold machine learning workflow. The clustering grouped data points based on similar petrophysical attributes without prior labeling. The cluster labels helped define the dependent variable in the subsequent predictive regression model. The combined approach (unsupervised + supervised learning) yielded an R² of 0.726 (train) and 0.723 (test) and RMSE of 0.232 (train) and 0.186 (test), indicating good predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce269fa-bbab-465b-b1ac-4e7feced5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723b35e-4323-40a7-8261-fa9855df6be3",
   "metadata": {},
   "source": [
    "Import data with features selected for the clustering task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ada4c9-9737-403e-90ad-4bd1d80b26d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Data/Mishra_et_al_2022/MAS_Well_Logs.xlsx')\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09cd8c1-82ca-469f-b64d-56e88a9ba5db",
   "metadata": {},
   "source": [
    "Data scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87273069-dc88-409e-b007-eb0fe6fa4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02d11f-36c5-47fe-b5fe-ff57aaa418ab",
   "metadata": {},
   "source": [
    "Elbow method for optimal K in k-Means clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e73a51-5339-45ce-b10d-9e47d09a5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_squared_distances = []\n",
    "K = range(1, 12)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(3, 2)) \n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b9598-ba63-4b44-a205-e4645120f3a4",
   "metadata": {},
   "source": [
    "Final model with 3 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728193fa-758c-4b81-97f3-c414b934804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "model = kmeans.fit(X)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785844bb-b9af-4d2c-ae0e-6ad734c793d2",
   "metadata": {},
   "source": [
    "Get cluster quality metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753cdb1-cf5b-4530-be0a-8bfa7b45e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette = metrics.silhouette_score(X, labels, metric='euclidean')\n",
    "calinski = metrics.calinski_harabasz_score(X, labels)\n",
    "print(\"Silhouette Score:\", silhouette)\n",
    "print(\"Calinski-Harabasz Score:\", calinski)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03483088-829f-4838-936a-641c3e3f2c55",
   "metadata": {},
   "source": [
    "Cluster centers visualization with first two components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ec435-e30c-4709-a223-88faaa7664ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "plt.figure(figsize=(5, 3))  \n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=10, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=50, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6a8a2-c0c8-4f89-8a6c-6aeca23410e2",
   "metadata": {},
   "source": [
    "PCA was applied in addition to clustering to reduce the complexity of the feature space and visually verify the distinctness of the K-Means clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626933d6-da17-4b26-bc9a-8e3d27f11c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd290c-5cb6-47e2-87ee-368438ebedca",
   "metadata": {},
   "source": [
    "Domain-based lithology classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd8f43-db9a-4a89-be3e-2a95f7d24a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions1 = [\n",
    "    (df['GR (API)'] > 0) & (df['GR (API)'] <= 2),\n",
    "    (df['GR (API)'] > 0) & (df['GR (API)'] <= 4),\n",
    "    (df['GR (API)'] > 4) & (df['GR (API)'] <= 14),\n",
    "    (df['GR (API)'] > 14) & (df['GR (API)'] <= 50),\n",
    "    (df['GR (API)'] > 50) & (df['GR (API)'] <= 75),\n",
    "    (df['GR (API)'] > 75) & (df['GR (API)'] <= 85),\n",
    "    (df['GR (API)'] > 85) & (df['GR (API)'] <= 100),\n",
    "    (df['GR (API)'] > 100) & (df['GR (API)'] <= 125),\n",
    "    (df['GR (API)'] > 125) & (df['GR (API)'] <= 200),\n",
    "    (df['GR (API)'] > 125)\n",
    "]\n",
    "values1 = [\n",
    "    'Anhydrite', 'Coal', 'Clean Sand', 'Shaley Sand', 'Sandy Shale',\n",
    "    'Silty Sand', 'Fine Siltstone', 'Muddy Siltstone',\n",
    "    'Claystone + Siltstone', 'Black Shale'\n",
    "]\n",
    "df['lithology1'] = np.select(conditions1, values1, default='Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcccaee-76df-4112-a8cd-5fc12562a3b8",
   "metadata": {},
   "source": [
    "Plot: PCA Colored by Lithology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f00fb-57fc-4cd0-bbc3-c3af8a1cffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA & classification\n",
    "finalDf = pd.concat([principalDf, df[['lithology1']]], axis=1)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(5, 3)) \n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlabel('Principal Component 1', fontsize=10)\n",
    "ax.set_ylabel('Principal Component 2', fontsize=10)\n",
    "ax.set_title('2 Component PCA by Lithology', fontsize=12)\n",
    "\n",
    "targets = ['Black Shale', 'Claystone + Siltstone', 'Muddy Siltstone', 'Fine Siltstone']\n",
    "colors = ['red', 'blue', 'orange', 'violet']\n",
    "for target, color in zip(targets, colors):\n",
    "    indicesToKeep = finalDf['lithology1'] == target\n",
    "    ax.scatter(\n",
    "        finalDf.loc[indicesToKeep, 'principal component 1'],\n",
    "        finalDf.loc[indicesToKeep, 'principal component 2'],\n",
    "        c=color, s=10, label=target\n",
    "    )\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4e0cd-455c-434b-96d8-ef35e8acbed8",
   "metadata": {},
   "source": [
    "The study projected high-dimensional well log data into a 2D PCA space, confirming clear separation between clusters and supporting the choice of K = 3 for k-means clustering. The 501 depth points were divided into three clusters of 241, 139, and 121, interpreted as representing shale, siltstone and claystone, and siltstone, respectively (via manual assignement). A strong correspondence was observed between cluster labels and lithology types, validating an underlying correlation between petrophysical log parameters and lithology. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f1e7f-55f1-44e5-b062-833b0cf95dfe",
   "metadata": {},
   "source": [
    "> ### **Exercise 2:** \n",
    "> Reflect on possible limitations with the applied clustering and it's interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf03bf4-8e67-4348-aaa2-3e705fb5bf50",
   "metadata": {},
   "source": [
    "## References and Further Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44523013-6fca-41b4-95e8-95664c5298d3",
   "metadata": {},
   "source": [
    "Chang, C.-H., Tan, S., Lengerich, B., Goldenberg, A., and Caruana, R.: How interpretable and trustworthy are gams?, doi:10.1145/3447548.3467453,    2021.\n",
    "\n",
    "Foy, B. de and Schauer, J. J.: Interpretable diurnal impacts on extreme urban PM2. 5 concentrations of soil temperature, soil water content, humidity and temperature inversion, Atmospheric Research, 307, 107500, doi:10.1016/j.atmosres.2024.107500,     2024.\n",
    "\n",
    "Dwivedi, R., Dave, D., Naik, H., Singhal, S., Omer, R., Patel, P., Qian, B., Wen, Z., Shah, T., and Morgan, G.: Explainable AI (XAI): Core ideas, techniques, and solutions, ACM Computing Surveys, 55, 1–33, doi:10.1145/3561048,      [Add to Citavi project by DOI] 2023.\n",
    "\n",
    "Denolle, M., Mehra, A., Todoran, S., Cristea, N., Arendt, A., Henderson, S., Sun, Z., Ni, Y., and Kharita, A.: Machine Learning in the Geosciences, **GeoSMART**, University of Washington eScience Institute, available at: https://geo‑smart.github.io/mlgeo-book/about_this_book/about_this_book.html, last access: 30 June **2025**.\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R., and Taylor, J.: An Introduction to Statistical Learning with Applications in Python, An Introduction to Statistical Learning: with Applications in Python, 1, 2023.\n",
    "\n",
    "Mishra, A., Sharma, A., and Patidar, A. K.: Evaluation and development of a predictive model for geophysical well log data analysis and reservoir characterization: Machine learning applications to lithology prediction, Natural Resources Research, 31, 3195–3222, doi:10.1007/s11053-022-10121-z,   2022.\n",
    "\n",
    "Molnar, C.: Interpretable Machine Learning: A Guide for Making Black Box Models Explainable (3rd ed.). Retrieved from christophm.github.io/interpretable-ml-book/, 2025.\n",
    "\n",
    "Schäfer, B., Beck, C., Rhys, H., Soteriou, H., Jennings, P., Beechey, A., and Heppell, C. M.: Machine learning approach towards explaining water quality dynamics in an urbanised river, Scientific Reports, 12, 12346, doi:10.1038/s41598-022-16342-9,   2022.\n",
    "\n",
    "[StatQuest with Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw) on YouTube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357937b1-b84a-4260-a2aa-3f63897fcec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
