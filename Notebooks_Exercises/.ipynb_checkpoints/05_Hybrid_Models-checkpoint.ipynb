{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea51bf7-572f-4a26-be71-2adcd41f20d7",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3f973-0f04-4d11-b508-b00b8f85a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2703a8-b48c-4631-a3e9-e542a48e2b39",
   "metadata": {},
   "source": [
    "# Hybrid Modeling\n",
    "\n",
    "Domain knowledge is encoded in the form of physical laws or process-based models. Rather than replacing this knowledge, machine learning (ML) can be combined with it. The goal of hybrid modeling is to achieve the best of both worlds: models that obey known physical laws and remain interpretable, yet are adaptive to data and capable of learning unknown dynamics. In practice, this means coupling physical process equations with ML components in various ways. Hybrid models often show improved predictive performance over both standalone process-based models and standalone ML. ML being incrementally introduced into geoscientific tools rather than completely switching to a black-box model facilitates adoption and trust, as the model’s core behavior can be evaluated against known benchmarks and theory. \n",
    "\n",
    "However, the trade-off with hybrid approaches is generally between enforcing known theory and allowing the network to discover new patterns. In addition, the chosen physics constraints or information must be correct and relevant. While these models do enforce known laws, the parts of the model that are learned (like a neural network (NN) representing an unknown functional relationship) can still be hard to interpret and may require post-hoc XAI methods to analyze (see Notebook 4). Furthermore, developing a robust hybrid model can be considerably more complex than working with either approach alone. \n",
    "\n",
    "This notebook provides a brief overview of hybrid modelling approaches, based on multiple comprehensive reviews that synthesized ongoing research and current use of ML and hybrid models in the geosciences (Reichstein et al. 2019; Irrgang et al. 2021; Shen et al. 2023; Zhao et al. 2024) and beyond (Meng et al. 2025; Cuomo et al. 2025). The table below provides the main categories of hybrid modeling approaches, classified by how ML and physical knowledge are combined, and the respective roles of each component. Across these use cases, hybrids can be weakly coupled (flow of information is mostly one-directional or the ML and PB components operate somewhat independently) or strongly coupled (dynamic two-way interaction). \n",
    "\n",
    "| **Category**                  | **Integration Strategy**                                                    | **ML Role**         | **Physics Role**                   |\n",
    "|------------------------------|------------------------------------------------------------------------------|---------------------|------------------------------------|\n",
    "| **1. Physics-informed ML**   | Physics added via constraints in loss functions, architecture, or data      | Primary model       | Constraints or priors              |\n",
    "| **2. ML inside PBMs**        | ML components embedded inside a physics-based model | Sub-component       | Structural backbone                |\n",
    "| **3. Surrogates/emulators**  | ML trained to approximate outputs of a physical model                       | Replacement model   | Source of training data            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d78f4d-0e7a-4e73-b3e9-516619ee32fa",
   "metadata": {},
   "source": [
    "## 1. Physics-informed or Physics-guided Machine Learning\n",
    "\n",
    "One broad class of hybrid methods can be termed physics-informed or physics-guided ML. Here, the primary model is a NN, but it is augmented with physical knowledge to improve its realism and generalization. The motivation is **to impose scientific consistency on data-driven models**, thereby mitigating problems like overfitting, data scarcity, and unrealistic outputs. There are several techniques to integrate physics into an ML model, including:\n",
    "\n",
    "- **Physics-based loss functions:** One common approach is adding penalty terms to the loss function of the network that represent deviations from known physical laws. This guides the learning process to satisfy conservation laws or other constraints. For example, in a deep learning model for lake temperatures, researchers included an energy conservation term in the loss (Read et al. 2019; Daw et al. 2022 - example below). The NN was trained not only to fit observed temperature data but also to minimize any violation of the lake heat budget. \n",
    "\n",
    "- **Architecture design and hard constraints:** Another avenue is building physics into the structure of the NN itself. This could mean encoding known invariants or symmetries (like conservation of energy or mass) directly into the model’s architecture, or using custom layers that implement physical operators. With this approach, outputs respect fundamental constraints (mass balance, energy, symmetry, etc.) by construction.\n",
    "\n",
    "- **Data augmentation with simulations:** Physics knowledge can also inform the training data itself. In many geoscience problems, real observations are limited or do not sample extreme events well. To address this, one can generate additional synthetic data from physics-based simulations or analytical solutions, and use these to train or pretrain the ML model. This approach was effectively used in the above lake temperature studies by pretraining the network on output from a process-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69da87b-26c0-4352-b3f9-dc5843ec6941",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This example, adapted from Daw et al. (2022), demonstrates how physics-guided NNs can combine physical principles with data-driven learning to improve the accuracy and realism of environmental predictions (here: lake temperature modeling).\n",
    "\n",
    "The core idea is to guide the training of a NN not only by its fit to observed data, but also by how well its predictions obey known physical laws. In the context of lake temperatures, one such law is that denser water tends to settle below lighter water, meaning that water density should increase with depth. Since water density is a known nonlinear function of temperature, we can use this relationship to impose a physical constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc062ee8-ea80-4d9f-bb06-aeb484def7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78072cbe-6ccd-4677-9ebd-3f8dccbbb25b",
   "metadata": {},
   "source": [
    "Define physical and statistical loss components in functions:\n",
    "- This is the standard empirical loss function, used to measure the prediction error (RMSE) between observed and predicted temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c2b48-0a1b-47b8-905a-4075a8af69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103daa3a-e065-4ec0-b746-0a06252a6e22",
   "metadata": {},
   "source": [
    "- This function models the nonlinear relationship between water temperature and density, which is central to the physical constraint. Water is densest at around 4°C, and this function encodes that physical behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea5d054-7fc7-4b98-9c0f-e67c9f1a081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(temp):\n",
    "    return 1000 * (1 - (temp + 288.9414) * (temp - 3.9863)**2 / (508929.2 * (temp + 68.12963)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c5d11-b8aa-4469-9b8f-a55698f4491c",
   "metadata": {},
   "source": [
    "- The following function defines the total loss used during training. It combines:\n",
    "    - Mean squared error on the observed temperatures, and\n",
    "    - A penalty for violating the density-depth rule (if upper layers are denser than lower ones). Only violations are penalized using ReLU, and λ (lambda) controls how strongly physics violations affect training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d7b9c-3c81-4140-aab2-40248a1691a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(params):\n",
    "    udendiff, lam = params\n",
    "    def loss(y_true, y_pred):\n",
    "        mse = K.mean(K.square(y_pred - y_true))       # MSE\n",
    "        penalty = lam * K.mean(K.relu(udendiff))       # Physics constraint\n",
    "        return mse + penalty\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0582f2d-83dc-4f99-88df-db5b75ace0a3",
   "metadata": {},
   "source": [
    "- This function is used as a separate metric to monitor how much the model violates the physics constraint, averaged across all unlabeled depth pairs (i.e., all samples in uX1 and uX2 - see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124562c0-bd4e-4988-b4df-eafc157e589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phy_loss_mean(params):\n",
    "    udendiff, lam = params\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.relu(udendiff))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a803ab-2430-4a12-8e68-98e51fb910ad",
   "metadata": {},
   "source": [
    "Load and prepare data:\n",
    "\n",
    "- We load the input features and observed temperatures for the Mille Lacs lake dataset provided with the study:\n",
    "    - Xc_doy: Input features\n",
    "    - Y: Observed temperatures (targets for supervised learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89255978-aa3d-4c96-b6c9-7106c6a11711",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Data/Daw_et_al_2022/datasets/\"\n",
    "lake_name = \"mille_lacs\"\n",
    "\n",
    "filename = f\"{data_dir}{lake_name}.mat\"\n",
    "mat = spio.loadmat(filename, squeeze_me=True, variable_names=['Y', 'Xc_doy', 'Modeled_temp'])\n",
    "\n",
    "Xc = mat['Xc_doy']\n",
    "Y = mat['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70d21a-3c3f-440c-a811-c726bb6eafe8",
   "metadata": {},
   "source": [
    "- We split the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2720be2-6366-4533-bfe6-4e2ef6b5f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = Xc[:3000, :], Y[:3000]\n",
    "testX, testY = Xc[3000:, :], Y[3000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742bf0d-35f9-47c1-b11f-8f13771b0d4b",
   "metadata": {},
   "source": [
    "- We also load unlabeled data, consisting of depth-paired features where physical constraints apply but temperature is not observed. This enables semi-supervised learning, where even unlabeled samples contribute to training via physics constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe8c5c-3fff-4f30-90b4-10cd878545f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_filename = f\"{data_dir}{lake_name}_sampled.mat\"\n",
    "unsup_mat = spio.loadmat(unsup_filename, squeeze_me=True, variable_names=['Xc_doy1', 'Xc_doy2'])\n",
    "\n",
    "# uX1 = input for shallower depth, uX2 = input for deeper depth\n",
    "uX1 = unsup_mat['Xc_doy1'] # Features at shallower depth\n",
    "uX2 = unsup_mat['Xc_doy2'] # Features at deeper depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f69d4-8327-4321-9548-37a37394c175",
   "metadata": {},
   "source": [
    "Define the NN:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ed51f-85df-4541-b111-74d629586fd5",
   "metadata": {},
   "source": [
    "We build a simple fully connected feedforward network that maps environmental inputs to predicted temperatures. No dropout is necessary and applied here, but it could be added to the network. Dropout layers are typically placed after dense (or other trainable) layers to regularize their outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa120a-14e3-4d02-96f9-fa55f30a65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # This creates a basic NN where layers are added one after another\n",
    "model.add(Dense(12, activation='relu', input_shape=(trainX.shape[1],)))  # Input layer: has 12 neurons; uses ReLU activation; inputs number of features as in training data\n",
    "# model.add(Dropout(0.0)) \n",
    "model.add(Dense(12, activation='relu')) # Hidden layer with 12 neurons\n",
    "# model.add(Dropout(0.0))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer: has 1 neuron; produces predicted temperature; uses linear activation (see Notebook 3; Sect. 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1453fb7-f1c8-47ec-9087-2bb41fc9d801",
   "metadata": {},
   "source": [
    "Apply the physics constraint:\n",
    "\n",
    "- We convert the unlabeled inputs (for depth-paired data) into TensorFlow constants. These are used to calculate predicted temperatures at different depths, enabling the physics penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28a1b9-76ae-4b94-a027-9b5860c68cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uin1 = tf.constant(uX1, dtype=tf.float32)  # shallower inputs\n",
    "uin2 = tf.constant(uX2, dtype=tf.float32)  # deeper inputs\n",
    "lam = tf.constant(100.0, dtype=tf.float32)  # λ: strength of physics penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f036ab9-7411-41ec-8488-54f3b1181bd4",
   "metadata": {},
   "source": [
    "- We compute the difference in water density between shallower and deeper predicted temperatures. If this difference is positive, it means denser water lies on top which is a violation of physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb05fa-6ec6-4690-b0bf-806125300e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uout1 = model(uin1)  # temperature prediction at shallow depth\n",
    "uout2 = model(uin2)  # temperature prediction at deeper depth\n",
    "\n",
    "udendiff = density(uout1) - density(uout2) # compute the difference: should be <= 0 (else, physics is violated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25346610-f818-410a-9c75-c68ff6c600dd",
   "metadata": {},
   "source": [
    "Compile the model with:\n",
    "- Combined loss (empirical + physics)\n",
    "- Adam optimizer (with gradient clipping to improve stability)\n",
    "- Metrics for both prediction accuracy and physics consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3720d-7829-4bf1-8cfe-95e8e57fc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=combined_loss([udendiff, lam]),           # Combined loss\n",
    "    optimizer=Adam(clipnorm=1.0),                  # Adam optimizer \n",
    "    metrics=[\n",
    "        phy_loss_mean([udendiff, lam]),            # Metric to monitor physics violation\n",
    "        root_mean_squared_error                    # RMSE on labeled data\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df3fde6-ff6a-4684-af3e-a3c6ef14e13c",
   "metadata": {},
   "source": [
    "We train the model using early stopping to prevent overfitting. If the validation loss doesn’t improve for 100 epochs, training halts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90043a78-b602-4a13-8954-644b665ffec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    trainX, trainY,\n",
    "    batch_size=1000,\n",
    "    epochs=100,\n",
    "    validation_split=0.1,  # Use 10% of training data for validation\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping, TerminateOnNaN()]  # Stop training if loss becomes NaN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb43c5-b5fc-4413-b6c0-25b34e262f17",
   "metadata": {},
   "source": [
    "Evaluate the trained model on test data:\n",
    "- Test RMSE to measure prediction accuracy.\n",
    "- Mean density violation to assess how well the model respects physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f07bdb-c834-46c1-9d37-f9b05a853093",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print(f\"Test RMSE (temperature error): {score[2]:.4f}\")\n",
    "print(f\"Physics Loss (mean density violation): {score[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1d24b-b541-449d-802b-bfed0994d8d0",
   "metadata": {},
   "source": [
    "- An RMSE of ~2.66°C means the model's average error is about 2.66 degrees, which may be acceptable depending on the domain and the typical temperature range.\n",
    "- 0.003 is a small value close to zero which means that in most depth pairs, the model respects the set physical constraint (few violations, or that any violations are very minor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8c2cd-fd8f-416b-86d8-07e3da4f105d",
   "metadata": {},
   "source": [
    "## 2. Machine Learning in Physical Models\n",
    "\n",
    "Another major category of integration focuses on enhancing process-based models with ML components. Instead of using ML as the primary model, here the backbone is a physical model (for instance, a climate model or hydrological model), which is augmented by learned elements. The idea is to retain the trusted core of physical models while using statistical learning to improve those aspects that are uncertain, empirical, or too complex to derive from first principles. There are multiple points where ML can be integrated:\n",
    "\n",
    "- Learning parameterizations: Physical models often contain tunable parameters or simplified subgrid parameterizations that represent unresolved processes (e.g. cloud microphysics, soil properties, vegetation traits). Traditionally these are set by empirical formulas or calibration. ML offers a way to learn optimal parameter values or relationships from data, rather than prescribing them. For example, instead of assigning fixed soil hydraulic parameters based on soil type, a ML model can be trained to map from easily observed soil and climate attributes to the best-fitting parameters for a given location. This was prototyped in hydrology by training a NN on data from thousands of catchments to predict catchment-specific model parameters, yielding a global hydrologic application that was more dynamic and data-informed (Beck et al. 2016).\n",
    "\n",
    "- Replacing empirical sub-models: If a particular component of a process-based model is highly empirical or uncertain in form, one can replace that sub-model with an ML model trained on data. This yields a hybrid model that is part mechanistic (for the well-understood processes) and part data-driven (for the poorly understood parts).\n",
    "\n",
    "- Bias correction and model output calibration: ML can be used in a post-processing role to correct systematic errors. Here, the physical model is run in the usual way, and an ML model is trained on the residuals or mismatches between model outputs and observations. The ML then learns to predict the bias as a function of relevant variables, allowing it to adjust the raw model output. Additionally, ML can aid in downscaling coarse model output to finer resolution by learning relationships between large-scale patterns and local outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7161ba-1f65-42fb-bb02-3551bf044067",
   "metadata": {},
   "source": [
    "## 3. Surrogates/ Emulators\n",
    "\n",
    "Surrogate modeling, also called emulation, refers to using ML to mimic a physical model. The goal is to create a fast and lightweight ML model that can reproduce the outputs of a much slower, more complex simulation. This is useful because many physical models (like those used in climate or hydrology) are computationally expensive. They can take hours or days to run. With a trained ML surrogate, one can predict results almost instantly, which makes it possible to explore many scenarios, tune parameters, or do optimization tasks that would otherwise be too slow. \n",
    "\n",
    "How it works:\n",
    "- Run the original physical model many times with different inputs (e.g., weather conditions, soil types, etc.).\n",
    "- Train a NN on this input–output data.\n",
    "- Use the ML model as a stand-in for the original simulator. It gives fast predictions that approximate what the physical model would have returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383d500-05d3-4fac-97cc-5cc7a5cf4fee",
   "metadata": {},
   "source": [
    "## References and Further Learning\n",
    "\n",
    "Cuomo, S., Di Cola, V. S., Giampaolo, F., Rozza, G., Raissi, M., and Piccialli, F.: Scientific machine learning through physics–informed neural networks: Where we are and what’s next, Journal of Scientific Computing, 92, 88, doi:10.1007/s10915-022-01939-z,    2022.\n",
    "\n",
    "Daw, A., Karpatne, A., Watkins, W. D., Read, J. S., and Kumar, V.: Physics-guided neural networks (pgnn): An application in lake temperature modeling, in: Knowledge guided machine learning, Chapman and Hall/CRC, 353–372, 2022.\n",
    "\n",
    "Irrgang, C., Boers, N., Sonnewald, M., Barnes, E. A., Kadow, C., Staneva, J., and Saynisch-Wagner, J.: Towards neural Earth system modelling by integrating artificial intelligence in Earth system science, Nat Mach Intell, 3, 667–674, doi:10.1038/s42256-021-00374-3,      2021.\n",
    "\n",
    "Meng, C., Griesemer, S., Cao, D., Seo, S., and Liu, Y.: When physics meets machine learning: A survey of physics-informed machine learning, Machine Learning for Computational Science and Engineering, 1, 1–23, doi:10.1007/s44379-025-00016-0,   2025.\n",
    "\n",
    "Read, J. S., Jia, X., Willard, J., Appling, A. P., Zwart, J. A., Oliver, S. K., Karpatne, A., Hansen, G. J. A., Hanson, P. C., and Watkins, W.: Process‐guided deep learning predictions of lake water temperature, Water Resources Research, 55, 9173–9190, doi:10.1029/2019WR024922,  2019.\n",
    "\n",
    "Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., and Prabhat: Deep learning and process understanding for data-driven Earth system science, Nature, 566, 195–204, doi:10.1038/s41586-019-0912-1,  2019.\n",
    "\n",
    "Shen, C., Appling, A. P., Gentine, P., Bandai, T., Gupta, H., Tartakovsky, A., Baity-Jesi, M., Fenicia, F., Kifer, D., and Li, L.: Differentiable modelling to unify machine learning and physical models for geosciences, Nature Reviews Earth & Environment, 4, 552–567, doi:10.1038/s43017-023-00450-9, 2023.\n",
    "\n",
    "Zhao, T., Wang, S., Ouyang, C., Chen, M., Liu, C., Zhang, J., Yu, L., Wang, F., Xie, Y., Li, J., Wang, F., Grunwald, S., Wong, B. M., Zhang, F., Qian, Z., Xu, Y., Yu, C., Han, W., Sun, T., Shao, Z., Qian, T., Chen, Z., Zeng, J., Zhang, H., Letu, H., Zhang, B., Wang, L., Luo, L., Shi, C., Su, H., Zhang, H., Yin, S., Huang, N., Zhao, W., Li, N., Zheng, C., Zhou, Y., Huang, C., Feng, D., Xu, Q., Wu, Y., Hong, D., Wang, Z., Lin, Y., Zhang, T., Kumar, P., Plaza, A., Chanussot, J., Zhang, J., Shi, J., and Wang, L.: Artificial intelligence for geoscience: Progress, challenges, and perspectives, Innovation (Cambridge (Mass.)), 5, 100691, doi:10.1016/j.xinn.2024.100691, 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91018a-f633-4dc2-83fb-70cee89e4284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
